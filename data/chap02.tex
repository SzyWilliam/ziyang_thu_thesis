% !TeX root = ../thuthesis-example.tex

\chapter{相关研究综述}

\section{分布式系统故障}

从可能不可靠的部件构建可靠的系统是分布式系统的基本挑战。
分布式系统中的每个节点，无论是服务器、网络链路还是软件进程，都容易受到各种类型的故障的影响。这些组件的互连性意味着一个区域的故障通常会像滚雪球一样蔓延，导致更广泛的系统服务中断。

导致系统组件故障产生的原因众多，包括软件缺陷和硬件故障等，例如进程崩溃、磁盘损坏、程序错误会导致单一组件失效，网络延迟和分区可能导致系统组件的连接和通信出现故障，从而产生级联的连锁反应。系统组件故障的频率不容忽视。通常来讲，系统单一组件发生故障的时间间隔服从指数分布，多个组件之间的故障时间间隔相互独立，从而导致在大型分布式系统中故障的频率很高。根据谷歌的相关研究\cite{beyer2016site}, 每年会有超过1/100的机器出现内存崩溃，在百台节点组成的计算机集群，每一亿个小时会出现五千次左右的故障。

根据系统组件故障的产生原因，我们可以将分布式系统故障划分为以下几种类别\cite{michaud20062}：

1. 外部环境导致的故障。该故障产生的原因为不受控制的系统外部环境，例如机房停电、电缆断裂、火灾、地震海啸和其他自然灾害等。这种类型的故障无法通过分布式系统自身来自动解决和恢复，通常需要系统的搭建者通过在多个分散的地理位置部署数据和服务的副本来避免系统的中断和业务的损失。

2. 系统硬件失效导致的故障。该故障产生的原因为系统中一个或多个硬件不再正常工作，例如磁盘写满、内存不足、网络延迟等。这种类型的故障通常是高可用方案的重点解决对象，通过多副本、自动容错机制可以有效地减少这种故障对系统的实际影响。

3. 系统软件异常导致的故障。该故障产生的原因为应用程序在运行时出现偏离预期的行为，例如在缓冲区的边界之外写入数据导致内存损坏和进程崩溃、除零错误、返回值错误等。该问题通常不易解决，但是高可用方案可以为这类错误提供一定的容错和兜底。

4. 外部恶意攻击导致的故障。该故障产生的原因为人为恶意行为，例如例如代码注入攻击和ddos攻击等。该类故障通常通过专门的安全防御解决，但高可用方案方案依然可以在ddos等部分攻击场景下提供帮助，例如通过负载均衡的能力重新分配资源，从而让系统部分节点在遭受攻击和崩溃时依然能够提供服务。

本文提出的高可用方案的目标是“部分失效、整体可用”。具体而言，即使出于上述的任何原因系统内有部分组件出现故障，只要系统剩余存活的组件满足可用标准、资源足够、能够协同工作，那么系统就可以通过故障检测、自动容错、自动恢复等高可用机制保证服务的正常运行，降低错误在用户侧的感知，保证业务的连续性。

具体而言，本文提出的高可用方案能能够解决Kola\cite{kola2005faults}等人提出的分布式系统错误，包括以下具体问题：

1. 进程宕机，一些进程长时间甚至无限期地挂起，无法响应外部的请求。从请求方的角度来看，没有简单的方法来确定进程是否还在提供服务或是已经无法响应，

2. 磁盘空间不足。在数据暂存和写入期间，磁盘空间不足。

3. 硬件/软件/网络中断。间歇性网络中断、由服务器/客户端机器崩溃引起的中断以及用于硬件/软件升级和错误修复的停机时间导致在此期间的相关任务、RPC请求全部失效。

4. 资源过度消耗。由于并发数量过多、内存资源支出太多导致服务器崩溃，或是引发大量抖动导致传输效率降低、各种任务超时。


\section{高可用和容错}

\subsection{定义和衡量指标}

高可用性(High Availability)是分布式数据库系统的关键特性。
高可用性是指系统在正常状态和各种故障状态下保持运行和可访问的能力。高可用能力对于系统可靠性、数据完整性和业务连续性至关重要，有助于帮助客户减少服务中断，保持业务弹性，从而避免收入损失和声誉受损，帮助客户企业满足各种法规遵从性要求，满足客户的期望。

高可用性可以通过服务级别协议SLA(Service Level Agreements)和恢复时间目标RTO/恢复点目标RPO等指标进行衡量。
SLA的关键指标是服务的正常运行百分比，例如目标为“五个九”的可用性意味着系统在一年中的 99.999\% 的时间都应处于运行状态，每年的服务停止时间不超过0.0001\%(即53分钟)。RTO 是指从服务中断到恢复服务所需的最长可接受时间，而 RPO 是指在发生中断后可能丢失数据的最大可接受量时间。

容错能力（Fault Tolerance）是指系统在部分组件发生故障后仍能继续正确运行的能力，也是实现高可用性的关键方法。容错的目标通常是实现零停机时间，这通常通过基础设施中每个组件的备份或冗余来实现。


\subsection{常见的高可用容错机制}

高可用性和容错能力的架构模式关键在于消除单点故障（single point failure）、对系统故障进行检测、在冗余节点之间可靠地进行故障转移（failover）。

单点故障是指系统中一旦失效就会导致整个系统崩溃的任何组件。高可用性通过复制关键组件，如服务器进程、数据存储设备，在节点之间建立对等关系而不是依赖中央枢纽等方法来避免单点故障。
持续监控系统状态、检测系统故障并建立自动化故障转移机制对高可用性起到至关重要的作用。在故障发生后，自动化故障转移机制能够检测到故障，并自动将操作切换到备用组件，从而最大限度地减少停机时间。


数据复制（Replication）是消除单点故障的重要方法。数据复制是指在不同位置创建和维护相同数据或者服务的多个副本，以确保数据或服务可用性和可靠性。同步复制确保数据被写入所有副本后才返回结果，异步复制则优先考虑可用性和性能，允许数据首先写入主节点，然后再复制到其他副本，这可能会导致临时的数据不一致。数据副本因子（replication factor）决定了存储的数据副本数量。


共识协议（Consensus Protocol）在维护多份数据副本的一致性，使得分布式系统中的多个副本或机器对状态达成一致。根据副本拓扑结构，共识协议可以分成单一领导者、多领导者、无领导者结构。
根据数据一致性分类，共识协议可以分成线性一致性\cite{herlihy1990linearizability}、顺序一致性\cite{attiya1994sequential}、最终一致性\cite{bailis2013eventual}。最终一致性中可以继续细化为因果一致性\cite{lloyd2011cops}、会话一致性\cite{mortazavi2018session}、读己之写一致性\cite{nishtala2013memcached}。Paxos、Raft、ZAB、Gossip是著名的共识算法。
Paxos\cite{lamport2001paxos}基于无领导拓扑结构实现了线性一致性语义，协议由Proposer、Acceptor、Learner三种身份的节点共同完成，通过两阶段协议实现多副本共识，在工业界有广泛应用，例如Google Chubby\cite{burrows2006chubby}和Google Spanner\cite{corbett2013spanner}，以及阿里巴巴的OceanBase\cite{zhen2014oceanbase}。
Raft\cite{ongaro2014raft}为单一领导者多追随者拓扑结构，提供了线性一致性语义。Raft通过大多数选举、状态机复制和日志一致性三个模块实现数据副本共识和安全性。Raft提出后被广泛运用在工业系统中，例如etcd\cite{etcd}和Apache Ratis\cite{ratis}。
ZAB\cite{junqueira2011zab}协议结构介于Paxos和Raft之间，由单一领导拓扑实现了强一致性。ZAB包含了Leader选举、数据发现、数据同步、全序原子广播四个阶段，是ZooKeeper\cite{hunt2010zookeeper}核心的一致性协议。
Gossip\cite{demers1987gossip}通过多副本无领导拓扑结构实现了最终一致性，由种子节点周期性选择邻居节点散步数据消息，最终同步给网络结构中的所有副本。节点往往采取last-writer-win算法来解决全局写入冲突。Gossip协议被运用在Apache Cassandra\cite{lakshman2010cassandra}和Consul\cite{mishra1993consul}等工业实现中。


故障转移和重试是常用的故障恢复方法。当系统中的主要副本发生故障或变得不可用时，系统自动或手动地将工作负载切换到其他副本上，通过在副本之间进行重试来确保服务的连续性和可用性。

故障转移机制的基础是故障检测和故障判定。
故障检测可以通过心跳机制进行健康检查，也可以依赖监控指标和日志进行人工分析，或者通过机器学习方法进行自动检测。故障判定可以基于规则算法（例如固定超时）、人工确认，或通过机器学习方法进行自动判断。
故障检测和判定的核心挑战在于在检测准确性和检测速度的两个维度上进行权衡。提高检测准确性通常意味着更低的误报率，代价是更慢的检测速度。而更快的检测速度往往意味着错报，触发不必要的故障转移。

故障转移机制的实现方法依赖在多副本之间重试。重试不但可以应对单一副本的非永久性的瞬时故障，例如网络抖动、短暂的资源过载等问题，也能通过将请求导引到其他副本上来应对单一副本的永久性故障，从而实现自动故障恢复，减少人工的干预和人力的投入。
根据不同的策略，重试可以分为立马重试、固定间隔等待重试、指数退避重试、随机退避重试和基于策略的重试方法。立马重试和固定间隔等待重试的实现简单，适用于预期故障能够快速恢复的场景，然而会给系统增加负载。
指数退避重试和随机退避重试是通过将每次重试之间等待的时间间隔设置成指数增长、增加随机抖动的方式缓解因频繁重试造成的系统压力，避免雪崩效应。基于策略的重试则需要请求的双方提前约定好不同的错误状态的含义和对应的重试策略，服务方根据对自身的状态评估给出一个错误状态交给请求方处理，提高重试的有效性。

故障恢复还包括对故障副本的自动修复。在数据库系统中，通常可以依赖消息日志（Message Logging）和检查点（Check-pointing）来实现。消息日志可以让系统记录所有关键操作或者状态变更，在系统出错之后依赖日志记录的顺序重新执行操作，即可完整恢复系统到故障前的状态。消息日志的现实应用场景包括数据库中的预写式日志（WAL）、Raft共识协议中的日志、分布式消息队列KafKa中的日志等。
检查点（Check-pointing）能够缩短故障恢复的时间。系统定期将其状态保存到可靠且稳定的存储介质上。崩溃后，系统从最后一个检查点重新启动并回放消息日志，而不是从头开始，大大缩短系统恢复时间。常见的检查点技术包括全量检查点、增量检查点和模糊检查点等，它们在性能和恢复速度上各有优劣。例如，LSM结构\cite{o1996lsmtree}的数据库会通过定期将内存中的MemTable刷盘形成SSTable，分布式计算框架Apache Spark\cite{zaharia2016spark}和Apache Flink\cite{carbone2015flink}也通过检查点技术来实现容错。


除了上述所言的反应式容错技术外，Ledmi\cite{ledmi2018fault}等人的研究还总结了主动式容错技术。
反应式容错（Reactive Fault Tolerance）指的是系统在发生故障之后采取措施进行恢复，而主动式容错（Proactive Fault Tolerance）指的是在系统发生故障之前就采取预防措施，预防故障的发生或减轻故障的影响。通常的步骤包括预测故障、预防故障、提前进行容错设计，核心思想是“防患于未然”。常见的主动式容错方案包含软件抗衰老（Software Rejuvenation）、预防式迁移（Preemptive Migration）、负载均衡（Load Balancing）等。

软件抗衰老通过定期或在特定条件下重启或刷新软件系统，以清除累积的错误状态和资源泄漏，从而防止系统崩溃或性能下降。系统在长时间运行过程中可能会积累内存泄漏、资源耗尽、线程死锁等问题，这些错误状态可能不会立即导致系统崩溃，但会逐渐降低系统的性能和稳定性。通过定期或在特定条件下重启或刷新系统，清除这些累积的错误状态，使系统恢复到健康状态。该技术在电信、航空航天、金融交易等系统中非常常见。

预防式迁移通常指预测到某个节点可能即将发生故障时，提前主动干预，服务或数据迁移到更安全或更稳定的节点上。这种预测通常基于系统的性能指标等内部状态信息、节点的负载信息和资源使用情况，或是在计划内的硬件维护、软件升级等之前。

负载均衡则通过将用户的请求或工作负载均匀地分配到多个服务器或组件上，从而主动避免单点故障。系统通常会部署多个能够提供服务的服务器，并通过将客户端的请求分发到多个服务器上，以平衡系统的负载，提高系统的整体性能和可用性，并允许服务增加服务器数量来实现系统的水平扩展，提高系统的容量和并发处理能力。在系统受到突发大流量压力的情况下，扩缩容配合负载均衡能够良好地扛住流量的压力，保障服务的平稳运行。



本文的高可用性和容错能力的建设主要集中在主动式容错机制的建设，即数据复制、共识协议、故障转移等方面。

本节的剩下部分将会对当代分布式系统中高可用性和容错性的实践展开研究。具体而言，本文会研究Cassandra、TiDB、Oceanbase三个成熟的分布式数据库系统的高可用和容错设计，作为后续IoTDB建设高可用性和容错能力借鉴和参考。



\section{Cassandra系统的高可用方案}
Cassandra\cite{lakshman2010cassandra}是一个开源的分布式NoSQL数据存储系统，用于管理分布在大量廉价服务器上的海量结构化数据，具备水平可扩展性、灵活的数据模型、没有单点故障的高可用性等优点。

\subsection{Cassandra系统整体架构}

\begin{figure}
  \centering
  \includegraphics[width=0.5\linewidth]{cassandra-arch.png}
  \caption{Cassandra系统整体架构图}
  \label{fig:cassandra-arch}
\end{figure}

Cassandra基本组成单元是节点（Node），节点代表单个运行Cassandra进程的实例，通常运行在成本较低的商用硬件上。Cassandra集群中通常由多个节点组成。每个节点是同质性的，提供和其他节点完全相同的功能。
节点是Cassandra线性可扩展性的基础，通过增加节点进行横向扩展，Cassandra可以增加其管理的数据量、服务的吞吐量。
节点直接通过叫做Gossip的一种P2P协议进行通信。

Cassandra上管理的数据会被进一步划分为更小粒度的分区，从而在各个节点中均匀分布数据。Cassandra通过一致性哈希算法\cite{karger1997consistent}决定每个节点负责的数据范围。分区情况会被Gossip协议广播到所有节点，从而使每个节点都能够对外提供正确的服务。

Cassandra通过数据副本来保证可用性和容错能力，通过一致性协议保证副本的一致性。
Cassandra通过复制因子（RF）为同一个分区保留多个副本，保证即使一个副本宕机，其他副本仍然可以满足请求，且副本可以被放置在不同的数据中心，从而获得更高的安全性和性能。Cassandra通过一致性级别（CL）来决定操作的一致性，表示在操作被视为成功之前，必须向协调器确认读取或写入操作的最小Cassandra节点数。


\subsection{节点故障检测}

Cassandra中的每个节点通过Gossip协议来定期交换彼此的信息，并使用Phi累积性故障(Phi Accrual)检测算法\cite{hayashibara2004spl}来判断某个节点是否出现故障。

每个节点定期（通常每秒一次）通过Gossip协议选择几个节点交换彼此的状态信息，包括节点的运行状态、负载信息、该节点已知集群中其他节点的信息，使得信息可以快速有效地传播到整个集群。Gossip协议是一种最终一致性协议，随着时间的推移，所有节点最终都会收敛到一致的集群状态。

Cassandra的Phi累积性故障检测算法会根据Gossip交换的状态信息来计算出某个节点失效的可能性，避免了简单的地使用超时机制，而是通过统计分析心跳间隔，来预测节点失效的概率。Phi Accrual检测器会记录节点之间心跳信息到达的时间间隔，计算出一个“Phi”值，表示节点失效的可能性。Cassandra会设置一个Phi阈值，当Phi值超过这个阈值时，就认为节点失效。Phi Accrual检测器能够根据网络状况动态调整在网络不稳定的情况下，它会降低Phi阈值，以避免误判，在网络稳定的情况下，它会提高Phi阈值，以提高检测的准确性。在瞬态网络问题期间，节点可能暂时无法访问。使用phi accrual可以更宽容的对待这类网络问题，减少不必要的节点失效判断。


\section{TiDB系统的高可用方案}
TiDB\cite{huang2020tidb}是开源的分布式关系性数据库，同时支持OLTP和OLAP的能力，具备水平扩缩容、金融级高可用、实时 HTAP、云原生、兼容MySQL生态等优势。

\subsection{TiDB的整体架构}

TiDB集群可以划分为位于中间代理层的TiProxy，位于计算层的TiDB，和位于存储层的TiKV和TiFlash，以及集群的协调节点PD(Placement Driver)。

\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{tidb-arch.png}
  \caption{TiDB系统整体架构图}
  \label{fig:tidb-arch}
\end{figure}

PD(Placement Driver)是集群的大脑，负责元信息管理，实时监控和调整集群节点的整体拓扑结构、每一个节点的数据分布情况。

TiKV和TiFlash是数据的存储节点。TiKV是具备分布式事务能力的键值存储引擎，而TiFlash是为查询负载专门优化的列式存储引擎。
数据的存储以Region作为单位，包含了一段Key的区间，TiKV通过Region来实现数据分区和负载均衡，并会为每一个Region维护多个副本来服务高可用性。

TiDB是无状态的计算节点，负责接受客户端的连接，对SQL解析和优化，生成分布式执行计划，并将计划转发给存储节点进行执行。

TiProxy是部署在客户端应用和TiDB之间代理节点，提供负载均衡、连接持久化、服务发现和其他功能。


\subsection{故障的检测和发现}

在TiDB集群中，PD负责检测定期交换心跳来维持对每个节点、每个Region和集群全体的拓扑的拓扑感知，并会在检测到错误的时候尝试自动恢复。TiDB Server会通过PD获取最新的数据分区和地址，生成对应的查询计划。TiProxy会保持对TiDB Server的检测和探活。

TiKV会定期向PD发送心跳包，交换的内容包括总磁盘容量和磁盘用量、节点承载的Region数量、数据写入和读取的负载情况、发送/接受的snapshot数量等相关信息。如果PD在一段时间内没有收到TiKV的心跳，那么就会认为该节点可能出现故障，将其状态标记为异常，并且综合考虑用户配置和集群实际情况，来判断是否将该节点从集群中移除，并进行相应的调度操作，例如将该TiKV上的Region进行迁移。

每一个Region的Raft Leader也会定期向PD发送心跳包，交换的内容包括Leader所在的位置、每一个Follower所在的位置、掉线的副本个数和该Region的写入/读取速度。当Leader掉线，其他的Follower节点可能会触发新的选举，同时若PD长时间没有收到心跳，也可能触发主动的Leader切换和副本的调度。

\subsection{最高级别的容灾能力}

通过多数据副本、多机房部署、多地分布部署，TiDB集群可以实现RPO为零，RTO在一分钟以内的目标，同时容忍单节点故障、数据中心故障、一整个城市级别的灾难。以下是对TiDB的两地三中心五副本的部署结构描述：




\section{Oceanbase系统的高可用方案}

Oceanbase是开源的分布式关系性数据库，兼具分布式架构的扩展性和集中式架构的性能优势，过单一引擎支持混合事务/分析处理（HTAP），具备强数据一致性、高可用性、高性能、在线扩展、与 SQL 和主流关系型数据库的高度兼容性等优势。

\subsection{Oceanbase的整体架构}

Oceanbase集群主要包括OBServer和OBProxy两个角色。每一个OBServer上都运行着Oceanbase的一个进程，内部可进一步细分为根服务(Root Service)、SQL引擎、事务引擎和存储引擎。OBProxy则充当中间层，接收来自应用程序的SQL请求将其路由到集群内最佳的OBServer节点，然后将执行结果返回给应用程序。

\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{oceanbase-arch.png}
  \caption{Oceanbase系统整体架构图}
  \label{fig:oceanbase-arch}
\end{figure}

根服务是集成在Oceanbase进程内的逻辑服务，负责维护集群的元数据，包括表结构、分区信息、节点状态等。根服务会通过心跳机制检测每一个OBServer的健康状况，如果发现故障，则会触发恢复流程，包括重新选举领导者或重新复制分区。根服务还会负责监控集群的负载情况，会进行分区移动、分区复制和领导者切换等操作，以确保各个节点的资源利用率均衡。

OBServer还包含了SQL引擎，用于接受用户请求并生成对应的计划，以及基于LSM结构的存储引擎。

集群内的元数据和用户数据都是以分区的方式进行水平划分和存储，并通过副本复制的方式保证分区的高可用。Oceanbase采用了基于哈希和范围的双层划分算法，但会保证同一个表组的分区被分配在同一个节点上。Oceanbase采用Paxos对每一个分区的redo log进行复制管理，在故障恢复的时候，通过重放redo log实现恢复。

OBProxy 用于将请求路由到 OBServer。当接收到用户的 SQL 查询时，OBProxy 将解析该查询，然后根据分区的位置信息将查询发送到相应的 OBServer，提供服务发现和负载均衡等能力。


\subsection{Oceanbase的快速故障发现}

OceanBase通过校验和、针对Paxos恢复和选举优化、基于RPC机制的节点检测等方式尽可能提前错误发生的时间。

在校验和上，Oceanbase在每次从磁盘中读写数据的时候都会计算和比较校验和，在每次大合并之后对每一个数据分区的副本重新比对校验和，在重放Redo Log的时候会计算每一条事务的累积校验和。通过事务粒度的校验和机制，Oceanbase能够发现软件实现中事务处理和并发控制两个模块的人为程序漏洞。

在Paxos算法上，Oceanbase通过大幅减少故障单元和稳定的选举算法来提高故障的发现能力。
在前文所提到的TiDB中，故障恢复单元是每一个Raft组。当上层业务的分区特别多、单一节点上承载的Raft数量特别多的情况下，故障恢复的单元数量就会水平扩张，量级巨大。然而，在Oceanbase 4.0版本之后，故障恢复的单元转变成一个单机的日志流，在逻辑上可以把每一个节点视作一个整体的Paxos组，因此故障恢复单元将不再和业务的元数据和实际数据量有关，从而进一步降低了故障恢复的复杂性和时间。
传统的Paxos选举流程基于随机算法，并且依赖节点之间的时钟同步，例如NTP。Oceanbase的实现消除了对节点间时钟同步的依赖，完全基于消息驱动，依靠节点之间的消息交互和顺序来触发选举，并激进地将Leader的Lease时间缩短到了4s以内，从而能够更快地检测到故障并完成新的Leader选举。

Oceanbase 4.0中，节点间健康状态监测机制从基于TCP的连接机制转变为基于RPC框架内部的方式。3.0版本中OceanBase采用定期发送TCP Keepalive的探测包来检测节点之间的网络连接是否正常，然而这种检测只能用于判断网络情况，如果OBServer进程出现问题（例如Coredump崩溃），但TCP连接依然存在，KeepAlive机制无法识别。因此，在4.0版本中，Oceanbase框架内值了健康状态监测机制，通过定期发送应用程序级别的心跳包，从而能同时监测网络和进程的健康。同时，由于RPC 框架内部的检测机制能够检测应用程序的响应延迟、错误率等指标，从而提供更细粒度的健康状态信息。

\subsection{Oceanbase的故障恢复和Client协同}

Oceanbase通过Paxos并行回放、故障时期领导指定、Client的建连探活等方式提高故障恢复的速度。

在前一节所述，Oceanbase的故障恢复单元是一个单一的Paxos Group，为了提高故障恢复的速度，Oceanbase需要进行并行、实时地回放日志中的事务，从而防止日志回放成为性能的瓶颈。在Oceanbase中，不同事务的Redo日志可以并行回放，同一事物的不同Redo日志也可以并行回放，通过事务的ID




\section{表格}

表应具有自明性。为使表格简洁易读，尽可能采用三线表，如表~\ref{tab:three-line}。
三条线可以使用 \pkg{booktabs} 宏包提供的命令生成。

\begin{table}
  \centering
  \caption{三线表示例}
  \begin{tabular}{ll}
    \toprule
    文件名          & 描述                         \\
    \midrule
    thuthesis.dtx   & 模板的源文件，包括文档和注释 \\
    thuthesis.cls   & 模板文件                     \\
    thuthesis-*.bst & BibTeX 参考文献表样式文件    \\
    \bottomrule
  \end{tabular}
  \label{tab:three-line}
\end{table}

表格如果有附注，尤其是需要在表格中进行标注时，可以使用 \pkg{threeparttable} 宏包。
研究生要求使用英文小写字母 a、b、c……顺序编号，本科生使用圈码 ①、②、③……编号。

\begin{table}
  \centering
  \begin{threeparttable}[c]
    \caption{带附注的表格示例}
    \label{tab:three-part-table}
    \begin{tabular}{ll}
      \toprule
      文件名                 & 描述                         \\
      \midrule
      thuthesis.dtx\tnote{a} & 模板的源文件，包括文档和注释 \\
      thuthesis.cls\tnote{b} & 模板文件                     \\
      thuthesis-*.bst        & BibTeX 参考文献表样式文件    \\
      \bottomrule
    \end{tabular}
    \begin{tablenotes}
      \item [a] 可以通过 xelatex 编译生成模板的使用说明文档；
        使用 xetex 编译 \file{thuthesis.ins} 时则会从 \file{.dtx} 中去除掉文档和注释，得到精简的 \file{.cls} 文件。
      \item [b] 更新模板时，一定要记得编译生成 \file{.cls} 文件，否则编译论文时载入的依然是旧版的模板。
    \end{tablenotes}
  \end{threeparttable}
\end{table}

如某个表需要转页接排，可以使用 \pkg{longtable} 宏包，需要在随后的各页上重复表的编号。
编号后跟表题（可省略）和“（续）”，置于表上方。续表均应重复表头。

\begin{longtable}{cccc}
    \caption{跨页长表格的表题}
    \label{tab:longtable} \\
    \toprule
    表头 1 & 表头 2 & 表头 3 & 表头 4 \\
    \midrule
  \endfirsthead
    \caption*{续表~\thetable\quad 跨页长表格的表题} \\
    \toprule
    表头 1 & 表头 2 & 表头 3 & 表头 4 \\
    \midrule
  \endhead
    \bottomrule
  \endfoot
  Row 1  & & & \\
  Row 2  & & & \\
  Row 3  & & & \\
  Row 4  & & & \\
  Row 5  & & & \\
  Row 6  & & & \\
  Row 7  & & & \\
  Row 8  & & & \\
  Row 9  & & & \\
  Row 10 & & & \\
\end{longtable}
