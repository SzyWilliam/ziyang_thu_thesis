% !TeX root = ../thuthesis-example.tex

\chapter{相关研究综述}

\section{分布式系统故障}

从可能出现故障的部件构建可靠的系统是分布式系统的基本挑战。
分布式系统中的每个节点，无论是服务器、网络链路还是软件进程，都容易受到进程崩溃、磁盘损坏、程序错误、网络延迟和分区等各种类型的故障的影响而出现单点中断。此外，互连的组件还可能会使故障像雪球一样传播和蔓延，产生级联的连锁反应。

系统组件故障的频率不容忽视。通常来讲，系统单一组件发生故障的时间间隔服从指数分布，多个组件之间的故障时间间隔相互独立，从而导致在大型分布式系统中故障的频率很高。根据谷歌的相关研究\cite{beyer2016site}，在谷歌内部集群每年会有超过1/100的机器出现内存崩溃，在百台节点组成的计算机集群中，每一亿个小时会出现五千次左右的故障。

根据系统组件故障的产生原因，我们可以将分布式系统故障划分为以下几种类别\cite{michaud20062}：

1. 外部环境导致的故障。该故障产生的原因为不受控制的系统外部环境，例如机房停电、电缆断裂、火灾、地震海啸和其他自然灾害等。这种类型的故障无法通过分布式系统自身来自动解决和恢复，通常需要系统的搭建者通过在多个分散的地理位置部署数据和服务的副本来避免系统的中断和业务的损失。

2. 系统硬件失效导致的故障。该故障产生的原因为系统中一个或多个硬件不再正常工作，例如磁盘写满、内存不足、网络延迟等。这种类型的故障通常是高可用方案的重点解决对象，通过多副本、自动容错机制可以有效地减少这种故障对系统的实际影响。

3. 系统软件异常导致的故障。该故障产生的原因为应用程序在运行时出现偏离预期的行为，例如在缓冲区的边界之外写入数据导致内存损坏和进程崩溃、除零错误、返回值错误等。该问题通常不易解决，但高可用方案可以为这类错误提供一定的容错和兜底。

4. 外部恶意攻击导致的故障。该故障产生的原因为人为恶意行为，例如代码注入攻击和DDoS攻击等。该类故障通常通过专门的安全防御解决，但高可用方案依然可以在DDoS等部分攻击场景下提供帮助，例如通过负载均衡的能力重新分配资源，从而让系统部分节点在遭受攻击和崩溃时依然能够提供服务。

本文提出的高可用方案的目标是“部分失效、整体可用”。具体而言，即使由于上述的任何原因导致系统内有组件出现故障，只要系统剩余存活的组件满足可用标准、资源足够、能够协同工作，那么系统就可以通过故障检测、自动容错、自动恢复等高可用机制保证服务的正常运行，降低错误在用户侧的感知，保证业务的连续性。

更具体来说，本文提出的高可用方案能够解决Kola\cite{kola2005faults}等人提出的分布式系统常见错误，包括

1. 进程宕机，一些进程长时间甚至无限期的挂起，无法响应外部的请求。从请求方的角度来看，没有简单的方法来确定进程是否仍在提供服务，或已经无法响应。

2. 磁盘空间不足。在数据暂存和写入期间，磁盘空间不足。

3. 硬件/软件/网络中断。间歇性网络中断、由服务器/客户端机器崩溃引起的中断以及用于硬件/软件升级和错误修复的停机时间导致在此期间的相关任务、RPC请求全部失效。

4. 资源过度消耗。由于并发数量过多、内存资源消耗太大导致服务器崩溃，或是引发大量抖动导致传输效率降低、各种任务超时。


\section{高可用和容错}

\subsection{定义和衡量指标}

高可用性（High Availability）是分布式数据库系统的关键特性。
高可用性是指系统在正常状态和各种故障状态下保持运行和可访问的能力。高可用能力对于系统可靠性、数据完整性和业务连续性至关重要。对客户而言，数据库的高可用性有助于帮助客户减少服务中断，避免收入损失和声誉受损，满足各种法规遵从性要求。


高可用性可以通过服务级别协议SLA（Service Level Agreements）和恢复时间目标RTO/恢复点目标RPO等指标进行衡量。
SLA指标是指服务的正常运行百分比，例如目标为“五个九”的可用性意味着系统在一年中的 99.999\% 的时间都应处于运行状态，每年的服务停止时间不超过0.0001\%(即53分钟)。
RTO 是指从服务中断到恢复服务所需的最长可接受时间，而 RPO 是指在发生中断后可能丢失数据的最大可接受量时间。
在本文的测试章节，将使用RTO和RPO指标衡量IoTDB服务的可用能力。

容错能力（Fault Tolerance）是指系统在部分组件发生故障后仍能继续正确运行的能力\cite{lee1990fault}，也是实现高可用性的关键方法。容错的目标通常是实现零停机时间，这通常通过基础设施中每个组件的备份或冗余来实现。


\subsection{常见的高可用容错机制}

高可用性和容错能力的架构模式关键在于消除单点故障（Single Point Failure）、对系统故障进行检测、在冗余节点之间可靠地进行故障转移（Failover）。

单点故障是指系统中一旦失效就会导致整个系统崩溃的任何组件。高可用性通过复制关键组件，如服务器进程、数据存储设备，在节点之间建立对等关系而不是依赖中央枢纽等方法来避免单点故障。

数据复制（Replication）是消除单点故障的重要方法。数据复制是指在不同位置创建和维护相同数据或服务的多个副本，以确保数据或服务可用性和可靠性。同步复制确保数据被写入所有副本后才返回结果，异步复制则优先考虑可用性和性能，允许数据首先写入主节点后直接返回，然后再由后台进程复制到其他副本，这可能会导致临时的数据不一致。数据副本因子（Replication Factor）决定了存储的数据副本数量。


共识协议（Consensus Protocol）用于维护多份数据副本的一致性，使得分布式系统中的多个副本或机器对状态达成一致。根据副本拓扑结构，共识协议可以分为单一领导者、多领导者、无领导者结构。
根据数据一致性分类，共识协议可以分为线性一致性\cite{herlihy1990linearizability}、顺序一致性\cite{attiya1994sequential}、最终一致性\cite{bailis2013eventual}。最终一致性可以进一步分为为因果一致性\cite{lloyd2011cops}、会话一致性\cite{mortazavi2018session}、读己之写一致性\cite{nishtala2013memcached}。Paxos、Raft、ZAB、Gossip是著名的共识算法。
Paxos\cite{lamport2001paxos}基于无领导拓扑结构实现了线性一致性语义，协议由Proposer、Acceptor、Learner三种身份的节点共同完成，通过两阶段协议实现多副本共识，在工业界有广泛应用，例如Google Chubby\cite{burrows2006chubby}和Google Spanner\cite{corbett2013spanner}，以及阿里巴巴的OceanBase\cite{zhen2014OceanBase}。
Raft\cite{ongaro2014raft}为单一领导者多追随者拓扑结构，提供了线性一致性语义。Raft通过大多数选举、状态机复制和日志一致性三个模块实现数据副本共识和安全性。Raft提出后被广泛运用在工业系统中，例如etcd\cite{etcd}和Apache Ratis\cite{ratis}。
ZAB\cite{junqueira2011zab}协议结构介于Paxos和Raft之间，由单一领导者拓扑实现了强一致性。ZAB包含了大多数选举、数据发现、数据同步、全序原子广播四个阶段，是ZooKeeper\cite{hunt2010zookeeper}核心的一致性协议。
Gossip\cite{demers1987gossip}通过多副本无领导拓扑结构实现了最终一致性，由种子节点周期性选择邻居节点传播数据消息，最终同步给网络结构中的所有副本。节点往往采取last-writer-win算法来解决全局写入冲突。Gossip协议被运用在Apache Cassandra\cite{lakshman2010cassandra}和Consul\cite{mishra1993consul}等工业实现中。


故障转移和重试是常用的故障恢复方法。当系统中的主要副本发生故障或变得不可用时，系统自动或手动地将工作负载切换到其他副本上，通过在副本之间进行重试来确保服务的连续性和可用性。

故障转移机制的基础是故障检测和故障判定。
故障检测可以通过心跳机制进行健康检查，也可以依赖监控指标和日志进行人工分析，或者通过机器学习方法进行自动检测。故障判定可以基于规则算法（例如固定超时）、人工确认，或通过机器学习方法进行自动判断。
故障检测和判定的核心挑战在于在检测准确性和检测速度的两个维度上进行权衡。提高检测准确性通常意味着更低的误报率，代价是更慢的检测速度。而更快的检测速度往往意味着错报，触发不必要的故障转移。

故障转移机制的实现方法依赖于在多副本之间重试。重试不仅可以应对单一副本的非永久性的瞬时故障，例如网络抖动、短暂的资源过载等问题，还能通过将请求导引到其他副本上来应对单一副本的永久性故障，从而实现自动故障恢复，减少人工干预和人力投入。
根据不同的策略，重试可以分为立即重试、固定间隔等待重试、指数退避重试、随机退避重试和基于策略的重试方法。立即重试和固定间隔等待重试的实现简单，适用于预期故障能够快速恢复的场景，但会给系统增加负载。
指数退避重试和随机退避重试通过将每次重试之间等待的时间间隔设置成指数增长、增加随机抖动的方式缓解因频繁重试造成的系统压力，避免雪崩效应。基于策略的重试则需要请求的双方提前约定好不同的错误状态的含义和对应的重试策略，服务方根据对自身状态的评估给出一个错误状态交给请求方处理，以提高重试的有效性。

故障恢复还包括对故障副本的自动修复。在数据库系统中，通常可以依赖消息日志（Message Logging）和检查点（Check-pointing）来实现。消息日志可以让系统记录所有关键操作或者状态变更，在系统出错之后依赖日志记录的顺序重新执行操作，即可完整恢复系统到故障前的状态。消息日志的实际应用场景包括数据库中的预写式日志（WAL）、Raft共识协议中的日志、分布式消息队列KafKa中的日志等。
检查点（Check-pointing）能够缩短故障恢复的时间。系统定期将其状态保存到可靠且稳定的存储介质上。崩溃后，系统从最后一个检查点重新启动并回放消息日志，而不是从头开始，大大缩短系统恢复时间。常见的检查点技术包括全量检查点、增量检查点和模糊检查点等，它们在性能和恢复速度上各有优劣。例如，LSM结构\cite{o1996lsmtree}的数据库会通过定期将内存中的MemTable刷盘形成SSTable，分布式计算框架Apache Spark\cite{zaharia2016spark}和Apache Flink\cite{carbone2015flink}也通过检查点技术来实现容错。


除了上述所言的反应式容错技术外，Ledmi\cite{ledmi2018fault}等人的研究还总结了主动式容错技术。
反应式容错（Reactive Fault Tolerance）指的是系统在发生故障之后采取措施进行恢复，而主动式容错（Proactive Fault Tolerance）指的是在系统发生故障之前就采取预防措施，预防故障的发生或减轻故障的影响。通常的步骤包括预测故障、预防故障、提前进行容错设计，核心思想是“防患于未然”。常见的主动式容错方案包含软件抗衰老（Software Rejuvenation）、预防式迁移（Preemptive Migration）、负载均衡（Load Balancing）等。

软件抗衰老通过定期或在特定条件下重启或刷新软件系统，清除累积的错误状态和资源泄漏，从而防止系统崩溃或性能下降。系统在长时间运行过程中可能会积累内存泄漏、资源耗尽、线程死锁等问题，这些错误状态可能不会立即导致系统崩溃，但会逐渐降低系统的性能和稳定性。通过定期或在特定条件下重启或刷新系统，清除这些累积的错误状态，使系统恢复到健康状态。该技术在电信、航空航天、金融交易等系统中非常常见。

预防式迁移通常指预测到某个节点可能即将发生故障时，提前主动干预，将服务或数据迁移到更安全或更稳定的节点上。这种预测通常基于系统的性能指标等内部状态信息、节点的负载信息和资源使用情况，或是在计划内的硬件维护、软件升级等之前。

负载均衡也是主动容错技术的常见办法，通过负载均衡算法，用户的请求会被均分到所有的服务器上，同样可以避免单点故障。系统通常会部署多个能够提供服务的服务器，并通过将客户端的请求分发到多个服务器上，以平衡系统的负载，提高系统的整体性能和可用性，并允许服务增加服务器数量来实现系统的水平扩展，提高系统的容量和并发处理能力。在系统受到突发大流量压力的情况下，扩缩容配合负载均衡能够良好地扛住流量的压力，保障服务的平稳运行。



本文的高可用性和容错能力的建设主要集中在主动式容错机制的建设，即数据复制、共识协议、故障转移等方面。

本节的剩余部分将研究成熟分布式系统中高可用性和容错性的实践。具体而言，本文会研究Cassandra、TiDB、OceanBase三个成熟的分布式数据库系统的高可用和容错设计，为后续IoTDB建设高可用性和容错能力提供借鉴和参考。



\section{Cassandra系统的高可用方案}
Cassandra\cite{lakshman2010cassandra}是一个开源的分布式NoSQL数据存储系统，用于管理分布在大量廉价服务器上的海量结构化数据，具备水平可扩展性、灵活的数据模型、无单点故障的高可用性等优点。

\subsection{Cassandra系统整体架构}

\begin{figure}
  \centering
  \includegraphics[width=0.5\linewidth]{cassandra-arch.png}
  \caption{Cassandra系统整体架构图}
  \label{fig:cassandra-arch}
\end{figure}

Cassandra的基本组成单元是节点（Node），节点代表单个运行Cassandra进程的实例，通常运行在成本较低的商用硬件上。

Cassandra集群通常由多个节点组成。每个节点是同质性的，都具备独立处理客户端读写请求的能力，任何一个节点都可以作为客户端请求的协调者，负责将请求转发给存储相关数据的其他节点。节点是Cassandra线性可扩展性的基础，通过增加节点进行横向扩展，Cassandra可以增加其管理的数据量、服务的吞吐量。

Cassandra 使用基于环的数据分布方式。集群中的节点在逻辑上组织成一个环状结构 。数据会被进一步划分为更小粒度的分区，通过一致性哈希算法\cite{karger1997consistent}分布在环上的各个节点中。每个节点被分配到环上的一段 token 范围，并负责存储和管理该范围内的所有数据。

\subsection{数据复制和共识协议}



Cassandra通过数据副本来保证可用性和容错能力，通过一致性协议保证副本的一致性。

Cassandra通过复制因子（RF）为同一个分区保留多个副本，保证即使一个副本宕机，其他副本仍然可以满足请求。副本可以被放置在不同的数据中心，从而获得更高的安全性和性能。

Cassandra通过一致性级别（CL）来决定操作的一致性，表示在操作被视为成功之前，必须向协调器确认读取或写入操作的最小Cassandra节点数。例如，在三个副本的情况下，用户可以将一致性级别设置为1/2/3，分别代表副本写入至少1/2/3个节点之后才能确认写入操作成功。除了指定具体的副本书，用户还可以将一致性设置为QUORUM，此级别要求大多数的副本节点成功确认写入操作；也可以将一致性级别设置成为ALL，这是最强的一致性级别，要求所有的副本节点都必须成功确认写入操作。

根据Cassandra 的官方文档和普遍实践，默认的一致性级别是1，因此写入操作只需要一个副本确认即可返回。这为Cassandra集群提供了最终一致性的保障。

\subsection{节点故障检测}\label{sec:cassandra-failure-detecttion}

Cassandra中的每个节点通过Gossip协议来定期交换彼此的信息，并使用Phi累积性故障（Phi Accrual）检测算法\cite{hayashibara2004spl}来判断某个节点是否出现故障。

每个节点定期（通常每秒一次）通过Gossip协议选择几个其他节点交换彼此的状态信息，包括节点的运行状态、负载信息、该节点已知集群中其他节点的信息，使得信息可以快速有效地传播到整个集群。Gossip协议是一种最终一致性协议，通过这种去中心化的方式，随着时间的推移，所有节点最终都会收敛到一致的集群状态。

Cassandra中的每个节点都在本地维护着一个故障检测器，采用Phi累积性故障检测算法来标记故障节点。故障检测器会根据 Gossip 协议接收到的其他节点的状态信息和历史记录，通过统计分析心跳间隔，来预测节点失效的概率，判断集群中的其他节点是否已经宕机或者已经从故障中恢复。这种机制会综合考虑网络的性能、节点的工作负载以及历史的运行状况，从而更准确地判断节点是否真正发生故障。用户可以通过调整$phi\_convict\_threshold$属性来控制故障检测器的灵敏度。较低的值会增加将无响应节点标记为宕机的可能性，而较高的值则会降低这种可能性，适用于网络环境不太稳定的场景。


\subsection{故障的容错和转移}

当客户端向 Cassandra 集群写入数据时，协调器节点会根据复制策略将写入操作发送给相应的副本节点。如果某个目标副本节点由于网络问题、硬件故障或其他原因而不可用时，协调器节点会将本次写入操作的相关信息（即“提示,hint”）存储在本地。等到宕机的节点恢复并重新加入集群时，协调器节点会检测到该节点的恢复，并将之前存储的提示转发给该节点，从而确保数据能够最终被写入到所有应该存储的副本上，实现数据的最终一致性。
提示信息中包含了目标宕机节点的位置、版本元数据以及实际需要写入的数据。
提示信息默认会在协调器节点上保存 3 小时，这个时间可以通过配置参数 $max\_hint\_window\_in\_ms$ 进行调整。


\section{TiDB系统的高可用方案}
TiDB\cite{huang2020tidb}是开源的分布式关系性数据库，同时支持OLTP和OLAP的能力，具备水平扩缩容、金融级高可用、实时 HTAP、云原生、兼容MySQL生态等优势。

\subsection{TiDB的整体架构}

TiDB集群可以划分为位于中间代理层的TiProxy，位于计算层的TiDB，位于存储层的TiKV和TiFlash以及集群的协调节点PD(Placement Driver)。

\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{related-tidb-arch.png}
  \caption{TiDB系统整体架构图}
  \label{fig:tidb-arch}
\end{figure}

PD（Placement Driver）是集群的管理服务，负责集群元数据、节点和数据分区的管理、监控和调整。PD使用Raft协议来保证自身的高可用和元数据的一致性。

TiKV和TiFlash是数据的存储节点。TiKV是具备分布式事务能力的键值存储引擎，而TiFlash是为查询负载专门优化的列式存储引擎。数据的存储以Region作为单位，包含了一段Key的区间，TiKV通过Region来实现数据分区和负载均衡，并会为每一个Region维护多个副本来保证高可用性，TiDB使用Raft作为副本的一致性协议。

TiDB是无状态的计算节点，在接收到来自客户端的连接之后，对传入的 SQL 语句进行解析和优化，并最终生成分布式执行计划，并将计划转发给存储节点执行。

TiProxy是部署在客户端应用和TiDB之间的代理节点，提供负载均衡、连接持久化、服务发现和其他功能。


\subsection{故障的检测和发现}

在TiDB集群中，PD负责对存储节点TiKV进行故障检测，TiProxy负责对TiDB进行故障检测。

TiKV会定期向PD发送心跳包，交换的内容包括总磁盘容量和磁盘用量、节点承载的Region数量、数据写入和读取的负载情况、发送/接收的snapshot数量等相关信息。如果PD在一段时间内没有收到TiKV的心跳，那么就会认为该节点可能出现故障，将其状态标记为异常，并且综合考虑用户配置和集群实际情况，来判断是否将该节点从集群中移除，并进行相应的调度操作，例如将该TiKV上的Region进行迁移。每一个Region的Raft Leader也会定期向PD发送心跳包，交换的内容包括Leader所在的位置、每一个Follower所在的位置、掉线的副本个数和该Region的写入/读取速度。当Leader掉线，其他的Follower节点可能会触发新的选举，同时若PD长时间没有收到心跳，也可能触发主动的Leader切换和副本的调度。


TiProxy会通过定期的健康检查来测试TiDB节点的状况，如果某个 TiDB 实例未能通过健康检查，负载均衡器就会停止向该实例转发流量，从而有效地将故障的 TiDB 实例隔离。



\subsection{故障的转移和恢复}

当PD检测到TiKV发生故障后，会启动主动的故障转移流程。首先，故障节点上的Raft Leader会在超时之后变得不可用，其他节点上的Follower副本会检测到这一超时并主动展开选举。同时，PD 还会将故障节点上的副本数据调度到其他的TiKV节点上进行复制以恢复到预期的副本数量，保障数据的冗余性。

PD节点的故障则通过Raft主动的Leader选举机制进行容错，只要集群中超过半数的 PD 节点是可用的，PD 集群就能继续正常工作。

由于 TiDB Server 是无状态的，单个或多个 TiDB Server 实例的故障不会导致数据丢失. 前端的负载均衡器会通过健康检查机制检测到故障的 TiDB Server，并停止向其转发流量，而是将请求转发给其他健康的 TiDB Server 实例。为了应对故障或增加处理能力，可以很容易地向集群中添加新的 TiDB Server 实例。

上述策略保证了系统整体的RPO为零，RTO为分钟级。


\section{OceanBase系统的高可用方案}

OceanBase是开源的分布式关系性数据库，兼具分布式架构的扩展性和集中式架构的性能优势，通过单一引擎支持混合事务/分析处理（HTAP），具备高性能、高可用性、强一致性、水平扩展性和兼容SQL生态等优势。

\subsection{OceanBase的整体架构}

OceanBase集群主要包括OBServer和OBProxy两个角色。每一个OBServer上都运行着OceanBase的一个进程，内部可进一步细分为根服务(Root Service)、SQL引擎、事务引擎和存储引擎。OBProxy则充当中间层，接收来自应用程序的SQL请求，将其路由到集群内最佳的OBServer节点，然后将执行结果返回给应用程序。

\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{related-OceanBase-arch.png}
  \caption{OceanBase系统整体架构图}
  \label{fig:OceanBase-arch}
\end{figure}

根服务是集成在OceanBase进程内的逻辑服务，负责维护集群的元数据，包括表结构、分区信息、节点状态等。根服务会通过心跳机制检测每一个OBServer的健康状况，如果发现故障，则会触发恢复流程，包括重新选举领导者或重新复制分区。根服务还会负责监控集群的负载情况，会进行分区移动、分区复制和领导者切换等操作以确保各个节点的资源利用率均衡。

OBServer还包含了SQL引擎，用于接收用户请求并生成对应的计划，以及基于LSM结构的存储引擎。

集群内的元数据和用户数据都是以分区（Partition）的方式进行水平划分和存储，并通过副本复制的方式保证分区的高可用。OceanBase采用了基于哈希和范围的双层划分算法，但会保证同一个表组的分区被分配在同一个节点上。OceanBase采用Paxos算法对每一个分区的重做日志进行复制管理，在故障恢复时，通过重放重做日志实现恢复。

OBProxy 用于将请求路由到 OBServer。当接收到用户的 SQL 查询时，OBProxy 将解析该查询，然后根据分区的位置信息将查询发送到相应的 OBServer，提供服务发现和负载均衡等能力。


\subsection{副本复制}

OceanBase 采用多副本机制来实现数据冗余，每个分区通常拥有三个副本，这些副本分布在不同的机房，以实现灾难恢复。OceanBase 采用基于 Paxos 协议的同步复制模型以确保跨副本的数据强一致性。数据复制是通过日志流机制实现的。Leader 副本上写入操作产生的重做日志会被复制到 Follower 副本 。Follower 副本会实时回放这些重做日志，以保持与 Leader 副本的一致性 。


\subsection{OceanBase的故障检测优化}

OceanBase通过校验和、针对Paxos恢复和选举优化、基于RPC机制的节点检测等方式，尽可能提前错误发生的时间。

在校验和上，OceanBase在每次从磁盘中读写数据的时候都会计算和比较校验和，在每次大合并之后对每一个数据分区的副本重新比对校验和，在重放Redo Log的时候会计算每一条事务的累积校验和。通过事务粒度的校验和机制，OceanBase能够发现软件实现中事务处理和并发控制两个模块的人为程序漏洞。

在Paxos算法上，OceanBase通过大幅减少故障单元和稳定的选举算法来提高故障的发现能力。
在前文所提到的TiDB中，故障恢复单元是每一个Raft组。当上层业务的分区特别多、单一节点上承载的Raft数量特别多的情况下，故障恢复的单元数量就会水平扩张，量级巨大。然而，在OceanBase 4.0版本之后，故障恢复的单元转变成一个单机的日志流，在逻辑上可以把每一个节点视作一个整体的Paxos组，因此故障恢复单元将不再和业务的元数据和实际数据量有关，从而进一步降低了故障恢复的复杂性和时间。
传统的Paxos选举流程基于随机算法，并且依赖节点之间的时钟同步，例如NTP。OceanBase的实现消除了对节点间时钟同步的依赖，完全基于消息驱动，依靠节点之间的消息交互和顺序来触发选举，并激进地将Leader的Lease时间缩短到了4s以内，从而能够更快地检测到故障并完成新的Leader选举。

OceanBase 4.0中，节点间健康状态监测机制从基于TCP的连接机制转变为基于RPC框架内部的方式。3.0版本中OceanBase采用定期发送TCP Keepalive的探测包来检测节点之间的网络连接是否正常，然而这种检测只能用于判断网络情况，如果OBServer进程出现问题（例如Coredump崩溃），但TCP连接依然存在，KeepAlive机制无法识别。因此，在4.0版本中，OceanBase框架内置了健康状态监测机制，通过定期发送应用程序级别的心跳包，从而能同时监测网络和进程的健康状态。同时，由于RPC 框架内部的检测机制能够检测应用程序的响应延迟、错误率等指标，从而提供更细粒度的健康状态信息。

\subsection{OceanBase的故障恢复}

OceanBase通过Paxos并行回放、故障时期领导指定、Client的建连探活等方式提高故障恢复的速度。

在前一节所述，OceanBase的故障恢复单元是一个单一的Paxos Group，为了提高故障恢复的速度，OceanBase需要进行并行、实时地回放日志中的事务，从而防止日志回放成为性能的瓶颈。在OceanBase中，不同事务的重做日志可以并行回放，同一事务的不同重做日志也可以并行回放，通过事务的ID来保证并发的安全性。

同时，当集群检测到节点故障时，对于Leader副本在这个节点上的Paxos组，根服务会直接指定组内的其他Follower副本展开选举，跳过随机心跳超时，在百毫秒的级别就把服务切换到一个新的副本上。这种方式有助于加速故障的恢复，减少总的RTO时间。

最后，OBProxy通过RPC请求的返回状态对OBServe进行存活判断，这种判断方式可能在队列请求积压或者整个节点负载升高的时候出现误判，导致 OBProxy 误把一个正常服务的节点标记在黑名单。因此，OBProxy会和节点建立一条单独的探测连接，只用于节点的存活分析，避免请求排队的影响。

\section{系统对比}


\begin{table}[h!]
  \centering
  \caption{不同系统之间的高可用和容错能力的比较}
  \label{tab:ha-comparison}
  \begin{tabular}{@{}lllll@{}}
      \toprule
      比较指标 & Apache Cassandra & TiDB & OceanBase\\
      \midrule
      数据多副本 & 多副本 & 多副本 & 多副本  \\
      一致性级别 & 最终一致性（默认） & 强一致性 & 强一致性  \\
      共识算法 & 异步复制和冲突修复 & Raft & Paxos\\
      故障检测算法 & 基于心跳的Phi累积性故障检测 & 心跳超时检测 & 心跳超时和基于连接的检测 \\
      集群服务高可用 & 所有节点同质提供 & 基于Raft的服务集群 & 基于 Paxos的服务集群 \\
      故障转移方法 &向副本转移& 向副本转移 & 向副本转移\\
      故障恢复方法 &协调者同步 & Raft主副本同步 & Paxos日志同步\\
      RPO & 0 & 0 & 0\\
      RTO & 分钟级& 分钟级 & 秒级\\



      \bottomrule
  \end{tabular}
\end{table}